{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立数据集/特征向量\n",
    "def create_data():\n",
    "    datasets = [['青年', '否', '否', '一般', '否'],\n",
    "               ['青年', '否', '否', '好', '否'],\n",
    "               ['青年', '是', '否', '好', '是'],\n",
    "               ['青年', '是', '是', '一般', '是'],\n",
    "               ['青年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '好', '否'],\n",
    "               ['中年', '是', '是', '好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '好', '是'],\n",
    "               ['老年', '是', '否', '好', '是'],\n",
    "               ['老年', '是', '否', '非常好', '是'],\n",
    "               ['老年', '否', '否', '一般', '否'],\n",
    "               ]\n",
    "    labels = [u'年龄', u'有工作', u'有自己的房子', u'信贷情况', u'类别']\n",
    "    # 返回数据集和每个维度的名称\n",
    "    return datasets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, labels = create_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信息熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_shannon_ent(dataset):\n",
    "    n = len(dataset) # 计算长度\n",
    "    label_counts = {} # 建立一个字典存储\n",
    "    # 统计每个类别出现的次数\n",
    "    for feature in dataset:\n",
    "        label = feature[-1]\n",
    "        if label not in label_counts:\n",
    "            label_counts[label] = 0     # 创建该元素并清零\n",
    "        label_counts[label] += 1\n",
    "    entropy = 0  # 存储信息熵\n",
    "    for key in label_counts:\n",
    "        p = float(label_counts[key]) / n  # 计算类概率，或者说类在所有数据中的比例\n",
    "        entropy -= p * log(p, 2)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_shannon_ent(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在某指定维度上对dataset进行划分，抽取某指定维度上等于value的特征\n",
    "def splite_dataset(dataset, axis, value):\n",
    "    splt_dset = []  # 定义一个列表用来存储value\n",
    "    for f in dataset:\n",
    "        if f[axis] == value:\n",
    "            reduce_fv = f[:axis]  # 此维度之前的所有列\n",
    "            reduce_fv.extend(f[axis+1:])  # 列表末尾插入此维度之后的所有列\n",
    "            splt_dset.append(reduce_fv)\n",
    "    return splt_dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['青年', '否', '好', '是'],\n",
       " ['青年', '是', '一般', '是'],\n",
       " ['中年', '是', '好', '是'],\n",
       " ['老年', '否', '好', '是'],\n",
       " ['老年', '否', '非常好', '是']]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splite_dataset(datasets, 1, '是')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算数据集中的主要类别，这里计算是借的多还是不借的多，其实就是判断yes多还是no多\n",
    "# 其他应用中可能会出现多个类别标签，因此这是一个通用函数\n",
    "def majority_cnt(classlist):\n",
    "    classcount = {}\n",
    "    for label in classlist:\n",
    "        if label not in classcount.keys():  # 字典的键中不包含label\n",
    "            classcount[label] = 0\n",
    "        classcount[label] += 1\n",
    "    # classcount.items()是以list形式返回字典的键值：dict_items([('yes', 2), ('no', 4)])\n",
    "    # key中指定值获取函数，x[1]表示用键值对第二个参数来排序\n",
    "    # reverse表示降序排序，默认是ascending\n",
    "    sorted_class_count = sorted(classcount.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_class_count[0][0]  # 返回出现次数最多的类的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['否', '否', '是', '是', '否', '否', '否', '是', '是', '是', '是', '是', '是', '是', '否']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'是'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classlist = [f[-1] for f in datasets] # 从数据集中抽取最后一列的值\n",
    "print(classlist)\n",
    "majority_cnt(classlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过遍历所有的特征，求取熵最小的划分方式\n",
    "# 返回划分数据最好的特征，和最大的信息增益\n",
    "def min_entropy_split_feature(dataset):\n",
    "    f_n = len(dataset[0]) - 1  # 特征数\n",
    "    base_entropy = calc_shannon_ent(dataset)  # 信息熵\n",
    "    best_info_gain = 0.0  # 定义变量存储最佳信息增益\n",
    "    #print(\"entropy calc:\"+str(dataset))\n",
    "    best_feature = -1\n",
    "    for i in range(f_n):\n",
    "        f_list = [feature[i] for feature in dataset] # 抽取数据集中第i+1个特征的值\n",
    "        unique_values = set(f_list)  # 去除该列重复的值\n",
    "        new_entropy = 0.0  # 存储条件熵\n",
    "        for value in unique_values:\n",
    "            sub_dataset = splite_dataset(dataset, i, value)  # 在某指定维度上对dataset进行划分，抽取某指定维度上等于value的特征\n",
    "            pro = len(sub_dataset) / float(len(dataset)) # 计算某指定特征中，每一个value的概率\n",
    "            new_entropy += pro * calc_shannon_ent(sub_dataset) # 计算条件熵\n",
    "        info_gain = base_entropy - new_entropy  # 信息增益是信息熵的减小量，也就是：信息熵-条件熵\n",
    "        if info_gain > best_info_gain:    # 条件判断，若信息增益大于最佳信息增益\n",
    "            best_info_gain = info_gain\n",
    "            best_feature = i\n",
    "    return best_feature, best_info_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0.4199730940219749)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_entropy_split_feature(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 利用ID3算法生成决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 递归构建决策树\n",
    "def create_tree(dataset, __labels):\n",
    "    labels = __labels.copy()\n",
    "    classlist = [f[-1] for f in dataset]\n",
    "    # 只剩下一个类了，因此返回类名称\n",
    "    if classlist.count(classlist[0]) == len(classlist): \n",
    "        return classlist[0]\n",
    "    # 数据集中只剩下最后一列了，也就是所有的特征都用完了，没法再向下分类了\n",
    "    # 这时候如果数据集中有多个类，那就认为是出现最多的那个类\n",
    "    # 实际中应该是，所给定的特征无法将数据进行完全分类导致的\n",
    "    if len(dataset[0]) == 1:\n",
    "        # print(\"******\")\n",
    "        return majority_cnt(classlist)\n",
    "    bestfeature = min_entropy_split_feature(dataset)[0] # 返回最好的特征\n",
    "    # if bestfeature >= len(labels):\n",
    "    #     print(\"**************index out of range\")\n",
    "    #     print(dataset)\n",
    "    #     print(labels)\n",
    "    #     print(bestfeature)\n",
    "    bestf_label = labels[bestfeature]\n",
    "    newtree = {bestf_label: {}} # 创建一个字典存储树，将best future作为根节点\n",
    "    del labels[bestfeature] # 删除该类别\n",
    "    f_values = [f[bestfeature] for f in dataset]  # 找出bestfeature全部取值\n",
    "    unique_f_values = set(f_values) # 去掉重复的值\n",
    "    for v in unique_f_values:\n",
    "        sublabels = labels[:]\n",
    "        _splitedtree = splite_dataset(dataset, bestfeature, v) # 在某指定维度上对dataset进行划分，抽取某指定维度上等于value的特征\n",
    "        # print(\"xxxxxxxxxxxxxx seperate:\")\n",
    "        # print(\"best fv:\" + str(bestfeature) + \" v:\" + str(v))\n",
    "        # print(_splitedtree)\n",
    "        # print(labels)\n",
    "        newtree[bestf_label][v] = create_tree(_splitedtree.copy(), sublabels) # 完成递归，在每个分支再调用函数\n",
    "    return newtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'有自己的房子': {'是': '是', '否': {'有工作': {'是': '是', '否': '否'}}}}\n"
     ]
    }
   ],
   "source": [
    "tree = create_tree(datasets, labels)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用构建好的决策树来进行分类\n",
    "def classify(input_tree, feature_labels, test_fv):\n",
    "    classlabel = \"none\"\n",
    "\n",
    "    first_label = list(input_tree.keys())[0]  # 获取字典中的第一个键位\n",
    "    new_dict = input_tree[first_label]  # 返回key中的value\n",
    "    feature_index = feature_labels.index(first_label)  # 获取first_label是第几个特征\n",
    "    for key in new_dict.keys():\n",
    "        if test_fv[feature_index] == key:  # 注意，key是特征的值\n",
    "            if type(new_dict[key]).__name__ == \"dict\":  # 如果key中的value类型为dict\n",
    "                classlabel = classify(new_dict[key], feature_labels, test_fv)# 进入下一分支\n",
    "            else:\n",
    "                classlabel = new_dict[key] # 返回标签\n",
    "    return classlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "否\n"
     ]
    }
   ],
   "source": [
    "x = classify(tree, labels, ['青年', '否', '否', '一般'])\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
